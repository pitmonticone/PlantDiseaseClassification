{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Plant Disease Classification\n",
    "\n",
    "### Additional Material \n",
    "\n",
    "* [GitHub Repository](https://github.com/InPhyT/NeuralNetworksProject)\n",
    "* [Report]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "### Train & Validation, Test Splitting\n",
    "\n",
    "This section has been run previously. The output dataset can be found in the input folder.\n",
    "\n",
    "```python\n",
    "\n",
    "src_dir = \"../input/plantvillage/images\" #r\"../plant-pathology-2020-fgvc7/images\"\n",
    "train_val_dst_dir = \"../working/train&val_images\" #r\"../plant-pathology-2020-fgvc7/train&val_images\" #\"../working/train&val_images\"\n",
    "test_dst_dir = \"../working/test_images\" #r\"../plant-pathology-2020-fgvc7/test_images\"  #\"../working/test_images\"\n",
    "\n",
    "if not os.path.isdir(train_val_dst_dir):\n",
    "    os.mkdir(train_val_dst_dir)\n",
    "if not os.path.isdir(test_dst_dir):\n",
    "    os.mkdir(test_dst_dir)\n",
    "\n",
    "\n",
    "if len([f for f in os.listdir(test_dst_dir)]) == 0:\n",
    "    all_images_names = os.listdir(src_dir)\n",
    "    train_val_images = []\n",
    "    test_images  = []\n",
    "    for image in all_images_names:\n",
    "        if \"Train\" in image:\n",
    "            shutil.copy(src_dir+\"/\"+image,train_val_dst_dir)\n",
    "        elif \"Test\" in image:\n",
    "            shutil.copy(src_dir+\"/\"+image,test_dst_dir)\n",
    "        else:\n",
    "            print(\"error\")\n",
    "\n",
    "# Check for possible errors\n",
    "total = len([f for f in  os.listdir(src_dir)])\n",
    "train_val_total = len([f for f in  os.listdir(train_val_dst_dir)])\n",
    "test_total = len([f for f in  os.listdir(test_dst_dir)])\n",
    "print(total == train_val_total + test_total)\n",
    "```\n",
    "[ ] : True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALL\n",
    "# Latest version of tensorflow, which comes with useful image loading APIs\n",
    "!pip install tf-nightly  # run only once per session\n",
    "\n",
    "# IMPORT\n",
    "\n",
    "% pylab inline         # Interactive numpy & matplotlib \n",
    "\n",
    "# Basic Utilities  \n",
    "import sys             # Enabler of operating system dependent functionality\n",
    "import os              # Provides access to some variables & functions for the interpreter\n",
    "import shutil          # Provides high-level operations on files and collections of files\n",
    "import math            # Provides access to basic mathematical functions\n",
    "\n",
    "## Data Manipulation & Analysis\n",
    "import pandas as pd    # Methods to manipulate, filter, group, and transform data\n",
    "import numpy as np     # Efficient storage and computation for multi-dimensional data arrays\n",
    "\n",
    "## Data Visualization \n",
    "import matplotlib      # Interface for creation of publication-quality plots and figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  # Matplotlib-based statistical data visualization interface \n",
    "### import plotly      # Interactive plotting library \n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "## Machine Learning \n",
    "### Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split # Split arrays or matrices into random train and test subsets\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "### TensorFlow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from imblearn.over_sampling import SMOTE # Class Balancing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "\n",
    "Here we get an insight of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle = True\n",
    "if kaggle:\n",
    "    outdir = r\"../working/\"\n",
    "    indir = r\"../input/plantvillage/\"\n",
    "else:\n",
    "    outdir = r\"Q:/tooBigToDrive/plantsvillage/temp/\"\n",
    "    indir = r\"Q:/tooBigToDrive/plantsvillage/\"\n",
    "    \n",
    "test_dir = indir + \"plantvillage_split_dataset/test_images\"\n",
    "train_labels_csv = pd.read_csv(indir+\"plantvillage_split_dataset/train.csv\")\n",
    "print(train_labels_csv.head())\n",
    "print(\"-------------------------------------\")\n",
    "example_submission_csv = pd.read_csv(indir+\"plantvillage_split_dataset/sample_submission.csv\")\n",
    "print(example_submission_csv.head() )\n",
    "print(\"-------------------------------------\")\n",
    "test_csv = pd.read_csv(indir+\"plantvillage_split_dataset/test.csv\")\n",
    "test_paths_csv= pd.DataFrame(test_csv[\"image_id\"].apply(lambda x: test_dir+\"/\"+x+\".jpg\"))\n",
    "print(test_paths_csv.head() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation Splitting\n",
    "This cell creates 4 directories (healthy, multiple_diseases, rust,scab) with the corresponding images from the train set. It is a very technical part that only has to do with the way TensorFlow expects the images to be organized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create csvs with images\n",
    "train_val_healthy_csv = train_labels_csv[train_labels_csv[\"healthy\"] == 1]\n",
    "train_val_multiple_diseases_csv  = train_labels_csv[train_labels_csv[\"multiple_diseases\"] == 1]\n",
    "train_val_rust_csv = train_labels_csv[train_labels_csv[\"rust\"] == 1]\n",
    "train_val_scab_csv = train_labels_csv[train_labels_csv[\"scab\"] == 1]\n",
    "# we will check that this has no entry\n",
    "two_classes = train_labels_csv[(train_labels_csv[\"scab\"] == 1) & (train_labels_csv[\"multiple_diseases\"] == 1)]\n",
    "\n",
    "train_val_healthy_names = train_val_healthy_csv[\"image_id\"].tolist()\n",
    "train_val_multiple_diseases_names = train_val_multiple_diseases_csv[\"image_id\"].tolist()\n",
    "train_val_rust_names = train_val_rust_csv[\"image_id\"].tolist()\n",
    "train_val_scab_names = train_val_scab_csv[\"image_id\"].tolist()\n",
    "\n",
    "src_dir = indir+\"plantvillage_split_dataset/train&val_images\" #\"../input/plantvillage/images\"\n",
    "train_dst_dir = outdir+\"train\" #\"../working/train&val_images\"\n",
    "\n",
    "#val_dst_dir = outdir+\"val\"  #\"../working/test_images\"\n",
    "train_dst_healthy_dir = outdir+\"train/healthy\"#\"../working/train&val_images\"\n",
    "train_dst_multiple_diseases_dir =outdir+\"train/multiple_diseases\"\n",
    "train_dst_rust_dir = outdir+\"train/rust\"\n",
    "train_dst_scab_dir = outdir+\"train/scab\"\n",
    "\n",
    "test_dst_dir = outdir + \"test_image/test\"\n",
    "\n",
    "# crreate the directories and fill them\n",
    "try:\n",
    "    os.mkdir(train_dst_dir)\n",
    "\n",
    "    os.mkdir(train_dst_healthy_dir)\n",
    "    os.mkdir(train_dst_multiple_diseases_dir)\n",
    "    os.mkdir(train_dst_rust_dir)\n",
    "    os.mkdir(train_dst_scab_dir)\n",
    "    os.makedirs(test_dst_dir)\n",
    "\n",
    "    for image in train_val_healthy_names :\n",
    "            shutil.copy(src_dir+\"/\"+image+\".jpg\",train_dst_healthy_dir)\n",
    "            \n",
    "    for image in train_val_multiple_diseases_names :\n",
    "            shutil.copy(src_dir+\"/\"+image+\".jpg\",train_dst_multiple_diseases_dir)\n",
    "\n",
    "    for image in train_val_rust_names :\n",
    "            shutil.copy(src_dir+\"/\"+image+\".jpg\",train_dst_rust_dir)\n",
    "\n",
    "    for image in train_val_scab_names :\n",
    "            shutil.copy(src_dir+\"/\"+image+\".jpg\",train_dst_scab_dir)\n",
    "\n",
    "    for image in test_paths_csv[\"image_id\"].tolist():\n",
    "        shutil.copy(image,test_dst_dir)\n",
    "        \n",
    "except FileExistsError as err:\n",
    "    print(\"folders already exist\")\n",
    " \n",
    "#check for possible errors\n",
    "total = len([f for f in  os.listdir(src_dir)])\n",
    "train_healthy_total = len([f for f in  os.listdir(train_dst_healthy_dir)])\n",
    "train_multiple_diseases_total = len([f for f in  os.listdir(train_dst_multiple_diseases_dir)])\n",
    "train_rust_total = len([f for f in  os.listdir(train_dst_rust_dir)])\n",
    "train_scab_total = len([f for f in  os.listdir(train_dst_scab_dir)])\n",
    "\n",
    "total = train_healthy_total + train_multiple_diseases_total +train_rust_total+ train_scab_total \n",
    "train_size = math.ceil(total*0.8)\n",
    "val_size = total - train_size\n",
    "test_size = test_csv.size \n",
    "image_size  = (200,200)\n",
    "batch_size = 32\n",
    "seed = 100\n",
    "print(train_healthy_total,train_multiple_diseases_total,train_rust_total,train_scab_total,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class balancing and Data Augmentation/Prepocessing\n",
    "This function performs class balancing and data augmentation. Classes are balanced with SMOTE, while data augmentation is performed with TesdorFlow's ImageDataGenerator. <br>\n",
    "Multiple variants of SMOTE and ImageDataGenerator have been tried, resulting in the following optimal configuration which also cares about performance. <br>\n",
    "Note that the function is split in two by the `valid` parameter: it allows to use the function to produce both the train and validation data and the train only. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_data(train_dst_dir , train_generator, val_generator, aug, batch_size, valid = True):\n",
    "    if valid:\n",
    "        # load data into tensorflow dataset: if we used the flow_form_directory method of the train_generator, it would be too slow\n",
    "        print(\"loading data...\")\n",
    "        train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        train_dst_dir,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=train_size, \n",
    "        )\n",
    "\n",
    "        val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "            train_dst_dir,\n",
    "            validation_split=0.2,\n",
    "            subset=\"validation\",\n",
    "            seed=1337,\n",
    "            image_size=image_size,\n",
    "            batch_size=val_size,\n",
    "        )\n",
    "        \n",
    "        print(\"augmenting train...\")\n",
    "        res = list(zip(*train_ds.unbatch().as_numpy_iterator()))\n",
    "        x_train = np.array(res[0])\n",
    "        print(\"x done\")\n",
    "        y_train = np.array(res[1])\n",
    "        yforpca = y_train\n",
    "        print(x_train.shape,y_train.shape)\n",
    "        unique, counts = numpy.unique(y_train, return_counts=True)\n",
    "        print(\"class distribution before smote = \", counts)\n",
    "        x_train  = np.array([image.flatten() for image in x_train ])\n",
    "        xforpca = x_train\n",
    "        print(\"flattened\")\n",
    "\n",
    "        smote_train = SMOTE(sampling_strategy = \"all\", random_state = 420,k_neighbors=10,n_jobs=4)   #svmsmote goes out of memory in all configs\n",
    "        x_train, y_train = smote_train.fit_resample(x_train, y_train)\n",
    "        x_train = np.reshape(x_train,(-1,200,200,3))\n",
    "        tot_train = len(x_train)\n",
    "        print(\"total_train after smote = \", x_train.shape)\n",
    "        yforpca1 = y_train #\n",
    "        xforpca1 = x_train  #\n",
    "        unique, counts = numpy.unique(y_train, return_counts=True)\n",
    "        print(\"class distribution after smote = \", counts)\n",
    "        y_train_cat = tf.keras.utils.to_categorical(\n",
    "            y_train, num_classes=4, dtype='float32'\n",
    "        )\n",
    "        \n",
    "        \n",
    "        train_generator.fit(x_train, seed = seed)\n",
    "        aug_train_images, aug_train_labels = train_generator.flow(x = x_train,y = y_train_cat,shuffle = False,batch_size = tot_train,seed = seed).next() \n",
    "        aug_train_images = np.array(aug_train_images)\n",
    "        aug_train_labels = np.array(aug_train_labels)\n",
    "        \n",
    "        # save memory\n",
    "        del x_train\n",
    "        #del y_train\n",
    "        del train_ds\n",
    "\n",
    "        out_train_datagen = ImageDataGenerator()\n",
    "        out_train_datagen.fit(aug_train_images)\n",
    "        out_train_flow = out_train_datagen.flow(aug_train_images,aug_train_labels,batch_size = batch_size,shuffle = False)\n",
    "\n",
    "        del aug_train_images\n",
    "        del aug_train_labels\n",
    "\n",
    "        print(\"train augmented, augmenting val...\")\n",
    "        #i = 0\n",
    "        res = list(zip(*val_ds.unbatch().as_numpy_iterator()))\n",
    "        x_val = np.array(res[0])\n",
    "        y_val = np.array(res[1])\n",
    "        y_val_cat = tf.keras.utils.to_categorical(\n",
    "            y_val, num_classes=4, dtype='float32'\n",
    "        )\n",
    "        print(x_val.shape,y_val.shape,y_val_cat.shape)\n",
    "        \n",
    "        \n",
    "        val_generator.fit(x_val)\n",
    "        aug_val_images, aug_val_labels = val_generator.flow(x = x_val,y = y_val_cat,shuffle = False,batch_size = val_size,seed = seed).next()\n",
    "        aug_val_images = np.array(aug_val_images)\n",
    "        aug_val_labels = np.array(aug_val_labels)\n",
    "\n",
    "        del x_val\n",
    "        del val_ds\n",
    "\n",
    "        out_val_datagen = ImageDataGenerator()\n",
    "        out_val_datagen.fit(aug_val_images)\n",
    "        out_val_flow = out_val_datagen.flow(aug_val_images,aug_val_labels,batch_size = val_size, shuffle = False)\n",
    "\n",
    "        del aug_val_images\n",
    "        del aug_val_labels\n",
    "        del res\n",
    "\n",
    "        print(\"returning\")\n",
    "        return (out_train_flow,out_val_flow,y_val,y_train,tot_train)\n",
    "    # if validation is not provided/ one intends to test\n",
    "    else:\n",
    "        print(\"loading data...\")\n",
    "        train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        train_dst_dir,\n",
    "        seed=1337,\n",
    "        image_size=image_size,\n",
    "        batch_size=train_size, \n",
    "        )\n",
    "        \n",
    "        print(\"augmenting train...\")\n",
    "        res = list(zip(*train_ds.unbatch().as_numpy_iterator()))\n",
    "        x_train = np.array(res[0])\n",
    "        y_train = np.array(res[1])\n",
    "        print(x_train.shape,y_train.shape)\n",
    "        unique, counts = numpy.unique(y_train, return_counts=True)\n",
    "        print(\"class distribution before smote = \", counts)\n",
    "        x_train  = np.array([image.flatten() for image in x_train ])\n",
    "        print(\"flattened\")\n",
    "        yforpca = y_train \n",
    "        xforpca = x_train  \n",
    "        smote_train = SMOTE(sampling_strategy = \"all\", random_state = 420,k_neighbors=10,n_jobs=4)\n",
    "        x_train, y_train = smote_train.fit_resample(x_train, y_train)\n",
    "        x_train = np.reshape(x_train,(-1,200,200,3))\n",
    "        yforpca1 = y_train \n",
    "        xforpca1 = x_train \n",
    "        unique, counts = numpy.unique(y_train, return_counts=True)\n",
    "        print(\"class distribution after smote = \", counts)\n",
    "        tot_train = len(x_train)\n",
    "        print(\"total_train after smote = \", x_train.shape)\n",
    "        \n",
    "        y_train_cat = tf.keras.utils.to_categorical(\n",
    "            y_train, num_classes=4, dtype='float32'\n",
    "        )   \n",
    "\n",
    "        train_generator.fit(x_train,seed = seed)\n",
    "        aug_train_images, aug_train_labels = train_generator.flow(x = x_train,y = y_train_cat,shuffle = False,batch_size = tot_train,seed = seed).next()\n",
    "        aug_train_images = np.array(aug_train_images)\n",
    "        aug_train_labels = np.array(aug_train_labels)\n",
    "\n",
    "        del x_train\n",
    "        del y_train\n",
    "        del train_ds\n",
    "\n",
    "        out_train_datagen = ImageDataGenerator()\n",
    "        out_train_datagen.fit(aug_train_images)\n",
    "        out_train_flow = out_train_datagen.flow(aug_train_images,aug_train_labels,batch_size = batch_size,shuffle = False)\n",
    "\n",
    "        del aug_train_images\n",
    "        del aug_train_labels\n",
    "        \n",
    "        return (out_train_flow,tot_train,xforpca,yforpca,xforpca1,yforpca1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set preprocessing\n",
    "The test set is preprocessed just as the validation set, in order to give the model the same feature distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmented_test(test_dir, test_generator):\n",
    "    test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        outdir + \"test_image\",\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"int\",\n",
    "        class_names=None,\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=test_size,\n",
    "        image_size=image_size,\n",
    "        shuffle = False,\n",
    "        seed=None,\n",
    "        validation_split=None,\n",
    "        subset=None,\n",
    "        interpolation=\"bilinear\",\n",
    "        follow_links=False,\n",
    "    )\n",
    "    \n",
    "    x_test = np.array([ array for array, label in test_ds.unbatch().as_numpy_iterator()])\n",
    "    test_generator.fit(x_test,seed = seed)\n",
    "    test_flow = test_generator.flow(\n",
    "        x= x_test,\n",
    "        y=None,\n",
    "        batch_size = test_size,\n",
    "        shuffle=False,seed = seed)\n",
    "\n",
    "    test_imgs = test_flow.next()\n",
    "\n",
    "    del test_ds\n",
    "    del x_test\n",
    "    del test_generator\n",
    "\n",
    "    return test_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators definition\n",
    "\n",
    "Visit https://keras.io/api/preprocessing/image/#imagedatagenerator-class for further details. One must note that preprocessing is different from augmenting: the former is referred to an well defined transformation applied to all data (in order to save memory, speed up execution etc...), while the latter to a random modification applied to a random sample of the data to train a more rubust model. So, (selected) augmenting techniques are applied to train only, while validation and test sets receive just the preprocessing applied to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "train_datagen = ImageDataGenerator(rotation_range=360,                # DATA AUGMENTATION\n",
    "                                   #shear_range=.25,                  # DATA AUGMENTATION\n",
    "                                   #zoom_range=.25,                   # DATA AUGMENTATION\n",
    "                                   #width_shift_range=.25,            # DATA AUGMENTATION\n",
    "                                   #height_shift_range=.25,           # DATA AUGMENTATION\n",
    "                                   rescale=1./255,                    # DATA MODIFICATION\n",
    "                                   #brightness_range=[.5,1.5],        # DATA AUGMENTATION\n",
    "                                   horizontal_flip=True,              # DATA AUGMENTATION\n",
    "                                   #vertical_flip=True                # DATA AUGMENTATION\n",
    "                                  )\n",
    "\n",
    "# VALIDATION\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# TEST\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# To train and validate\n",
    "train_flow_80, val_flow, y_val, y_train,total_train_80 = create_augmented_data(train_dst_dir  = train_dst_dir,train_generator = train_datagen, val_generator = val_datagen , aug = 5, batch_size = batch_size )\n",
    "train_flow,total_train,x,y,xS,yS = create_augmented_data(train_dst_dir  = train_dst_dir,train_generator = train_datagen, val_generator = val_datagen , aug = 5, batch_size = 32, valid = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA & SVD \n",
    "\n",
    "### SVD\n",
    "\n",
    "Plot the projection of the train+test sets on the plane identified by the two directions that retain most variance, before and after applying smot applying SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_LSA(test_data, test_labels, plot=True):\n",
    "        lsa = TruncatedSVD(n_components=2)\n",
    "        lsa.fit(test_data)\n",
    "        lsa_scores = lsa.transform(test_data)\n",
    "        color_mapper = {label:idx for idx,label in enumerate(set(test_labels))}\n",
    "        color_column = [color_mapper[label] for label in test_labels]\n",
    "        colors = [\"orange\",\"blue\",\"red\",\"green\"]\n",
    "        if plot:\n",
    "            plt.scatter(lsa_scores[:,0], lsa_scores[:,1], s=8, alpha=.8, c=test_labels, cmap=matplotlib.colors.ListedColormap(colors))\n",
    "            #plt.legend(handles=[orange_patch, blue_patch], prop={'size': 20})\n",
    "\n",
    "x_train  = np.array([image.flatten() for image in x ])\n",
    "x_trainS  = np.array([image.flatten() for image in xS ])\n",
    "\n",
    "del x,xS\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "fig.add_subplot(121)\n",
    "plot_LSA(x_train, y)\n",
    "plt.title(\"pre_SMOTE\")\n",
    "fig.add_subplot(122)\n",
    "plot_LSA(x_trainS, yS)\n",
    "plt.title(\"post_SMOTE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA\n",
    "\n",
    "Although the two plots above show that the dataset (assuming its signal to be greater than noise) does not live on a linear submanifold, below we plot its principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(x_trainS)\n",
    "\n",
    "U = pca.transform(x_trainS)\n",
    "S = pca.explained_variance_\n",
    "V = pca.components_\n",
    "\n",
    "print (\"U.shape = \", U.shape)\n",
    "print (\"S.shape = \",S.shape)\n",
    "print (\"V.shape = \", V.shape)\n",
    "\n",
    "plt.rc(\"image\", cmap=\"binary\")\n",
    "plt.figure(figsize=(8,5))\n",
    "for i in range(15):\n",
    "    plt.subplot(3,5,i+1)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(x_train[i].reshape(200,200,3)))\n",
    "    plt.title(y[i])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "print(\"plot the first principal components\")\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(V[i].reshape(200,200,3)))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "print(\"plot less relevant principal components\")\n",
    "plt.figure(figsize=(8,5))\n",
    "for i in range(10):\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(V[200+i].reshape(200,200,3)))\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the explained variance as function of principal directions retained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_cumsum = np.cumsum(pca.explained_variance_)/(pca.explained_variance_).sum()\n",
    "ev_at90 = ev_cumsum[ev_cumsum<0.9].shape[0]\n",
    "print (ev_at90)\n",
    "\n",
    "plt.plot(ev_cumsum)\n",
    "plt.vlines(ev_at90, 0, 1, linestyles='dashed')\n",
    "plt.hlines(0.9, 0, 500, linestyles='dashed');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Implementation\n",
    "\n",
    "### callbcks defintions\n",
    "\n",
    "Here we instantiate a learning rate modifier (callback), whose purpose is to ramp up the learning rate during the inital epoch using an empirically validated functional form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "ES_monitor=EarlyStopping(monitor='val_loss',\n",
    "                          patience=20)\n",
    "\n",
    "\n",
    "def build_lrfn(lr_start=0.00001, lr_max=0.00005, \n",
    "               lr_min=0.00001, lr_rampup_epochs=5, \n",
    "               lr_sustain_epochs=1, lr_exp_decay=.8):\n",
    "\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_rampup_epochs:\n",
    "            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n",
    "        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) *\\\n",
    "                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n",
    "                                - lr_sustain_epochs) + lr_min\n",
    "        return lr\n",
    "    return lrfn\n",
    "\n",
    "\n",
    "lrfn =  build_lrfn(lr_sustain_epochs = 7)\n",
    "lrfnd =  build_lrfn(lr_sustain_epochs = 5,lr_rampup_epochs=8)\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)\n",
    "lr_scheduled = tf.keras.callbacks.LearningRateScheduler(lrfnd, verbose=1)\n",
    "rng = [i for i in range(20+1)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "plt.plot(rng, y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as L\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.optimizers import Adam , RMSprop\n",
    "\n",
    "#the pre -trained densenet121\n",
    "def get_deeper_model():\n",
    "    #reg = .0005\n",
    "    \n",
    "    METRICS = [ \n",
    "      tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "      tf.keras.metrics.AUC(name='categorical_auc',multi_label=True),\n",
    "        ]\n",
    "    \n",
    "    model = tf.keras.Sequential([DenseNet121(input_shape=(200, 200, 3),\n",
    "                                weights='imagenet',\n",
    "                                include_top=False),\n",
    "                                L.GlobalAveragePooling2D(),\n",
    "                                L.Dense(4,activation='softmax')])\n",
    "        \n",
    "    model.compile(optimizer='adam',\n",
    "                loss = 'categorical_crossentropy',\n",
    "                metrics=METRICS)\n",
    "    \n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# an explicit keras model (EKM)\n",
    "def get_model(drop):\n",
    "    \n",
    "    METRICS = [ \n",
    "      tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "      tf.keras.metrics.AUC(name='categorical_auc',multi_label=True),\n",
    "        ]\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
    "\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)), #, input_shape=(150, 150, 3)\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(drop),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "\n",
    "    model.compile(RMSprop(lr=5e-4,momentum = 0.1),loss='categorical_crossentropy', metrics = METRICS)\n",
    "\n",
    "    # Model Summary\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models with validation\n",
    "the following cel trains the EKM on 80% of training data and validates on the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "drops =[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "val_loss =[]\n",
    "max_val_loss_epoch = []\n",
    "val_acc = []\n",
    "max_val_acc_epoch = []\n",
    "val_auc = []\n",
    "max_val_auc_epoch = []\n",
    "histories = []\n",
    "epochs_l = []\n",
    "for drop in drops:\n",
    "    i = 1\n",
    "    model = get_model(drop)\n",
    "    history = model.fit_generator(train_flow_80,\n",
    "                steps_per_epoch = total_train_80 // batch_size, #train_size//batch_size\n",
    "                epochs=80, # the model never seems to suffer from validation loss increase (even up to 100 epochs)\n",
    "                validation_data=val_flow,\n",
    "                validation_steps=1,\n",
    "                #callbacks = [lr_schedule],                  # we tried early stopping and learning rate scheduling, but they proved inefficient due to the high loss swipes we had during training.\n",
    "                workers=4)   \n",
    "    val_loss.append(np.max(np.array(history.history[\"val_loss\"])))\n",
    "    val_acc.append(np.max(np.array(history.history['val_categorical_accuracy'])))\n",
    "    val_auc.append(np.max(np.array(history.history['val_categorical_auc'])))\n",
    "    epochs_l.append(np.argmax(np.array(history.history['val_categorical_auc'])))\n",
    "    histories.append(history)\n",
    "    print(\"drop  = \",drop, \"done, next...\")\n",
    "    \n",
    "history  = histories[np.argmax(np.array(val_auc))]\n",
    "drop = drops[np.argmax(np.array(val_auc))]\n",
    "epochs = epochs_l[np.argmax(np.array(val_auc))]+1 #epochs = np.argmax(np.array(history.history[\"val_categorical_auc\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best drop = \", drop,\"best epochs = \", epochs)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize = (15,15))\n",
    "axs[0].set_title(\"val_loss\")\n",
    "axs[0].set_xlabel(\"dropout\")\n",
    "axs[0].set_ylabel(\"val_loss\")\n",
    "axs[0].plot(drops, val_loss)\n",
    "\n",
    "axs[1].set_title(\"val_acc\")\n",
    "axs[1].set_xlabel(\"dropout\")\n",
    "axs[1].set_ylabel(\"val_acc\")\n",
    "axs[1].plot(drops, val_acc)\n",
    "\n",
    "axs[2].set_title(\"val_auc\")\n",
    "axs[2].set_xlabel(\"dropout\")\n",
    "axs[2].set_ylabel(\"val_loss\")\n",
    "axs[2].plot(drops, val_auc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeper_model = get_deeper_model()\n",
    "deeper_history = deeper_model.fit_generator(train_flow_80,\n",
    "            steps_per_epoch = total_train_80 // batch_size, #train_size//batch_size\n",
    "            epochs=20, # the model never seems to suffer from validation loss increase (even up to 100 epochs)\n",
    "            validation_data=val_flow,\n",
    "            validation_steps=1,      # we tried early stopping and learning rate scheduling, but they proved inefficient due to the high loss swipes we had during training.\n",
    "            workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=np.arange(1, 100+1), mode='lines+markers', y=history.history['categorical_accuracy'], marker=dict(color=\"dodgerblue\"),\n",
    "                name=\"Train acc\"))\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=np.arange(1, 100+1), mode='lines+markers', y=history.history['val_categorical_accuracy'], marker=dict(color=\"darkblue\"),\n",
    "                name=\"Val acc\"))\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=np.arange(1, 100+1), mode='lines+markers', y=history.history['categorical_auc'], marker=dict(color=\"orange\"),\n",
    "                name=\"Train auc\"))\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(x=np.arange(1, 100+1), mode='lines+markers', y=history.history['val_categorical_auc'], marker=dict(color=\"orangered\"),\n",
    "                name=\"Val auc\"))\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(title_text=\"\", yaxis_title= \"Metrics\", xaxis_title=\"Epochs\", template=\"plotly_white\")\n",
    "\n",
    "    fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EKM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_train_history(deeper_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=False):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EKM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict_generator(val_flow, train_size // batch_size +1) #128 +1\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "a = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "plot_confusion_matrix(a,[\"h\",\"d\",\"c\",\"f\"],normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = deeper_model.predict_generator(val_flow, train_size // batch_size +1) #128 +1\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "a = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "plot_confusion_matrix(a,[\"h\",\"d\",\"c\",\"f\"],normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numba import cuda \n",
    "# device = cuda.get_current_device()\n",
    "# device.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the models on all data and predict test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save memory\n",
    "del y,yS\n",
    "del train_flow_80, y_train, val_flow, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test\n",
    "test_imgs = get_augmented_test(test_dir = test_dir, test_generator = test_datagen)\n",
    "print(test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test and prepare EKM submisision\n",
    "\n",
    "model1 = get_model(drop) #0.4\n",
    "model1.fit_generator(train_flow,\n",
    "            steps_per_epoch = total_train // batch_size, #train_size//batch_size\n",
    "            epochs=epochs,\n",
    "            #callbacks=[lr_schedule],\n",
    "            workers=4)\n",
    "\n",
    "def tensorSort(data):\n",
    "    return sorted(data, key=lambda item: (int(item.partition(' ')[0])\n",
    "                               if item[0].isdigit() else float('inf'), item))\n",
    "\n",
    "y_predicted = model1.predict(test_imgs)\n",
    "submission = pd.DataFrame(y_predicted, columns = [\"healthy\", \"multiple_diseases\", \"rust\",\"scab\"],)\n",
    "submission.insert(0,\"image_id\",tensorSort(test_csv[\"image_id\"].tolist()))\n",
    "submission.to_csv(\"../working/submission.csv\", index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test and prepare DenseNet submission\n",
    "\n",
    "\n",
    "deeper_model1 = get_deeper_model()\n",
    "\n",
    "\n",
    "deeper_model1.fit_generator(train_flow,\n",
    "            steps_per_epoch = total_train // batch_size, #train_size//batch_size\n",
    "            epochs=20,\n",
    "            #callbacks=[lr_scheduled],\n",
    "            workers=4)\n",
    "\n",
    "def tensorSort(data):\n",
    "    return sorted(data, key=lambda item: (int(item.partition(' ')[0])\n",
    "                               if item[0].isdigit() else float('inf'), item))\n",
    "\n",
    "y_predicted = deeper_model1.predict(test_imgs)\n",
    "submission = pd.DataFrame(y_predicted, columns = [\"healthy\", \"multiple_diseases\", \"rust\",\"scab\"],)\n",
    "submission.insert(0,\"image_id\",tensorSort(test_csv[\"image_id\"].tolist()))\n",
    "submission.to_csv(\"../working/deeper_submission.csv\", index = False)\n",
    "submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters and Feature Maps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image as pil_image\n",
    "from tensorflow.keras.preprocessing.image import save_img\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot\n",
    "from numpy import expand_dims\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import tensorflow.keras.layers as L\n",
    "\n",
    "# Import module we'll need to import our custom module\n",
    "from shutil import copyfile\n",
    "\n",
    "# Copy our file into the working directory (make sure it has .py suffix)\n",
    "copyfile(src = \"../input/filter-visualization-modules/conv_filter_visualization.py\", dst = \"../working/conv_filter_visualization.py\")\n",
    "copyfile(src = \"../input/othermodules/model.py\", dst = \"../working/model.py\")\n",
    "copyfile(src = \"../input/othermodules/viz.py\", dst = \"../working/viz.py\")\n",
    "copyfile(src = \"../input/othermodules/utils.py\", dst = \"../working/utils.py\")\n",
    "\n",
    "# Import all functions\n",
    "from conv_filter_visualization import *\n",
    "\n",
    "# Models\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Visualization (InPhyT Model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import glob\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.Sequential([\n",
    "   # tf.keras.Input(shape=(150, 150, 3)),\n",
    "    #data_augmentation(inputs),\n",
    "#     tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "#     tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "#     tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
    "    # The first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)), #, input_shape=(150, 150, 3)\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a dense layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 128 neuron in the fully-connected layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # 5 output neurons for 5 classes with the softmax activation\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', metrics = ['categorical_accuracy'],optimizer='adam')\n",
    "\n",
    "# Model Summary\n",
    "model.summary()\n",
    "\n",
    "# redefine model to output right after the first hidden layer\n",
    "model = Model(inputs=model.inputs, outputs=model.layers[1].output)\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "# layer_name = '' \n",
    "input_image = \"../input/plantvillage/plantvillage_split_dataset/test_images/Test_100.jpg\" \n",
    "\n",
    "# retrieve weights from the second hidden layer\n",
    "filters, biases = model.layers[1].get_weights()\n",
    "\n",
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "\n",
    "# plot first few filters\n",
    "n_filters, ix = 7, 1\n",
    "for i in range(n_filters):\n",
    "    # get the filter\n",
    "    f = filters[:, :, :, i]\n",
    "    # plot each channel separately\n",
    "    for j in range(3):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = pyplot.subplot(n_filters, 3, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        pyplot.imshow(f[:, :, j], cmap='gray') \n",
    "        ix += 1\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Map Visualization (InPhyT Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # tf.keras.Input(shape=(150, 150, 3)),\n",
    "    # data_augmentation(inputs),\n",
    "    # tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "    # tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    # tf.keras.layers.experimental.preprocessing.Rescaling(1./255),\n",
    "    # Note the input shape is the desired size of the image 200x 200 with 3 bytes color\n",
    "    \n",
    "    \n",
    "    # The first convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(224, 224, 3)), # input_shape=(150, 150, 3)\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a dense layer\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # 128 neuron in the fully-connected layer\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    # 5 output neurons for 5 classes with the softmax activation\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# redefine model to output right after the first hidden layer\n",
    "ixs = [2,3,4,5,6,7,8, 9, 10]\n",
    "outputs = [model.layers[i].output for i in ixs]\n",
    "model = Model(inputs=model.inputs, outputs=outputs)\n",
    "# load the image with the required shape\n",
    "img = load_img(input_image, target_size=(224, 224))\n",
    "# convert the image to an array\n",
    "img = img_to_array(img)\n",
    "# expand dimensions so that it represents a single 'sample'\n",
    "img = expand_dims(img, axis=0)\n",
    "# prepare the image (e.g. scale pixel values for the vgg)\n",
    "img = preprocess_input(img)\n",
    "# get feature map for first hidden layer\n",
    "feature_maps = model.predict(img)\n",
    "# plot the output from each block\n",
    "square = 5\n",
    "\n",
    "#fig, ax = subplots(figsize=(18, 2))\n",
    "#ax.imshow(random.rand(8, 90), interpolation='nearest'\n",
    "\n",
    "for fmap in feature_maps:\n",
    "    # plot all 64 maps in an 8x8 squares\n",
    "    ix = 1\n",
    "    plt.figure(figsize = (15,15))\n",
    "    for _ in range(square):\n",
    "        for _ in range(square):\n",
    "            # specify subplot and turn of axis\n",
    "            ax = pyplot.subplot(square, square, ix)\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # plot filter channel in grayscale\n",
    "            try:\n",
    "                pyplot.imshow(fmap[0, :, :, ix-1], cmap = 'gray')\n",
    "            except:\n",
    "                print(\"\", end = \"\\r\")\n",
    "            ix += 1\n",
    "    # show the figure\n",
    "    pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
